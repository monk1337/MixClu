{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mixclu import *\n",
    "\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df     = pd.read_csv('./datasets/church.txt')\n",
    "labels = df.pop('labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col, cat_col, con_col = get_types(df)\n",
    "con_col.extend(id_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores      = pd.DataFrame()\n",
    "predictions = pd.DataFrame()\n",
    "predictions['Label'] = labels\n",
    "data        = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FAMD_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-67e396e1207f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fg = FAMD_2(df)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m fg = famd_kemans(df, \n\u001b[0m\u001b[1;32m      4\u001b[0m                 \u001b[0mcat_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mclusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MixClu/mixclu/models.py\u001b[0m in \u001b[0;36mfamd_kemans\u001b[0;34m(df, cat_columns, clusters, random_state, max_iter, verbose, df_output)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mdf\u001b[0m         \u001b[0;34m=\u001b[0m \u001b[0mcobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mfmd_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFAMD_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     k_result   = kmeans_model(fmd_matrix, \n",
      "\u001b[0;31mNameError\u001b[0m: name 'FAMD_2' is not defined"
     ]
    }
   ],
   "source": [
    "# fg = FAMD_2(df)\n",
    "\n",
    "fg = famd_kemans(df, \n",
    "                cat_col, \n",
    "                clusters = 4, \n",
    "                random_state = 32, \n",
    "                max_iter = 300, \n",
    "                verbose = 0, \n",
    "                df_output = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = evaluate_clusters(scores,  list(yu['clusters']),\n",
    "                           labels, name='FAMD_Kmeans', \n",
    "                           X=EMD)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yu = kmeans_model(fg, \n",
    "                 4, \n",
    "                 random_state = 32, \n",
    "                 max_iter     = 300, \n",
    "                 verbose      = 0, \n",
    "                 df_output    = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_famd(df, \n",
    "                cat_columns, \n",
    "                total_clusters,\n",
    "                famd_feat_no = 5,\n",
    "                famd_iter    = 3,\n",
    "                random_state = 42,\n",
    "                kmax_iter    = 300, \n",
    "                verbose      = 0, \n",
    "                df_output    = False):\n",
    "    \n",
    "    \"\"\"model : 4\"\"\"\n",
    "    \n",
    "    df_famd          = famd_feats(df, cat_columns, famd_feat_no, famd_iter)\n",
    "    \n",
    "    result           = kmeans_model(df              = df_famd, \n",
    "                                     no_of_clusters = total_clusters, \n",
    "                                     random_state   = random_state, \n",
    "                                     max_iter       = kmax_iter, \n",
    "                                     verbose        = verbose, \n",
    "                                     df_output      = df_output)\n",
    "    return result,df_famd\n",
    "\n",
    "\n",
    "\n",
    "res, EMD = kmeans_famd(df, \n",
    "                cat_col, \n",
    "                4,\n",
    "                famd_feat_no = 9,\n",
    "                famd_iter    = 300,\n",
    "                random_state = 32,\n",
    "                kmax_iter    = 300, \n",
    "                verbose      = 0, \n",
    "                df_output    = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['clusters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = evaluate_clusters(scores,  list(yu['clusters']),\n",
    "                           labels, name='FAMD_Kmeans', \n",
    "                           X=EMD)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scores = evaluate_clusters(scores,  res['clusters'],\n",
    "                           labels, name='FAMD_Kmeansq', \n",
    "                           X=fg)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmoid_grower(df, \n",
    "                   cat_columns, \n",
    "                   no_of_clusters, \n",
    "                   metric       = 'precomputed', \n",
    "                   method       = 'pam', \n",
    "                   init         = 'build', \n",
    "                   max_iter     = 300, \n",
    "                   random_state = 4, \n",
    "                   df_output    = False):\n",
    "    \n",
    "    gower_distance_matrix = calculate_gower_distance(df, cat_columns)\n",
    "    model_e               = kmedoid_model(gower_distance_matrix, \n",
    "                                          no_of_clusters, \n",
    "                                          metric       = metric , \n",
    "                                          method       = method, \n",
    "                                          init         = init, \n",
    "                                          max_iter     = max_iter, \n",
    "                                          random_state = random_state, \n",
    "                                          df_output    = df_output)\n",
    "    \n",
    "    return model_e, gower_distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gro = kmoid_grower(df, \n",
    "                   cat_col, \n",
    "                   4, \n",
    "                   metric       = 'precomputed', \n",
    "                   method       = 'pam', \n",
    "                   init         = 'build', \n",
    "                   max_iter     = 300, \n",
    "                   random_state = 32, \n",
    "                   df_output    = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gro[0]['clusters']\n",
    "model_gro[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gower_distance33(df):\n",
    "  \n",
    "  '''\n",
    "  Takes a dataframe as an input and returns the gower distance\n",
    "  matrix.\n",
    "  \n",
    "  '''\n",
    "\n",
    "  variable_distances = []\n",
    "  \n",
    "  for col in range(df.shape[1]):\n",
    "    \n",
    "    feature = df.iloc[:,[col]]\n",
    "    if feature.dtypes.values == np.object:\n",
    "      \n",
    "      feature_dist = DistanceMetric.get_metric('dice').pairwise(pd.get_dummies(feature, drop_first=True))\n",
    "        \n",
    "    else:\n",
    "      \n",
    "      feature_dist = DistanceMetric.get_metric('manhattan').pairwise(feature) / max(np.ptp(feature.values),1)\n",
    "\n",
    "\n",
    "      variable_distances.append(feature_dist)\n",
    "      \n",
    "\n",
    "  return np.array(variable_distances).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def kmedoids_model(df):\n",
    "    \n",
    "    \n",
    "    \n",
    "    gower_data              = data.copy()\n",
    "    \n",
    "gower_distance_matrix   = calculate_gower_distance(gower_data)\n",
    "umap_embeddings         = umap.UMAP(random_state=42, n_components=2).fit_transform(gower_distance_matrix)\n",
    "\n",
    "gower_data['x']         = umap_embeddings[:,0]\n",
    "gower_data['y']         = umap_embeddings[:,1]\n",
    "gower_data['target']    = [str(x) for x in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 4\n",
    "random_state = 32\n",
    "\n",
    "\n",
    "\n",
    "# gower_data[\"preds\"] = list(model_gro['clusters'])\n",
    "# gower_data[\"preds\"] = [str(k) for k in list(model_gro['clusters'])]\n",
    "\n",
    "# predictions['gower_preds'] = gower_clusterer.labels_\n",
    "\n",
    "scores = evaluate_clusters(scores, list(model_gro[0]['clusters']),\n",
    "                           labels, \n",
    "                           name='gower_matrix_kmediods_pam', \n",
    "                           X=model_gro[1])\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design base models first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "id_col, cat_col, con_col = get_types(df)\n",
    "id_col, cat_col, con_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = ['State', \"Int'l Plan\", 'VMail Plan', 'Churn?']\n",
    "con_col = ['Account Length', 'VMail Message', 'Day Mins', 'Day Calls', \n",
    "           'Day Charge', 'Eve Mins', 'Eve Calls', 'Eve Charge', 'Night Mins', \n",
    "           'Night Calls', 'Night Charge', 'Intl Mins', 'Intl Calls', \n",
    "           'Intl Charge', 'CustServ Calls']\n",
    "\n",
    "df_pre = autopreprocessing(df, \n",
    "                  cat_col, \n",
    "                  id_columns      = None,\n",
    "                  con_colmns      = con_col,\n",
    "                  y               = None, \n",
    "                  allowed_missing = 20.0, \n",
    "                  corr_thr        = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df          = df_pre[0]\n",
    "con_columns = con_col\n",
    "cat_columns = cat_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Model : 1\"\"\"\n",
    "\n",
    "# 1. Cluster based on continuous data only\n",
    "\n",
    "\n",
    "df_cos = df[con_columns]\n",
    "result = kmeans_model(df_cos, 5, df_output = False)\n",
    "result\n",
    "# print(list(result['clusters'])[:10], y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Model : 2\"\"\"\n",
    "\n",
    "# 1. Cluster based on mix data with one hot encoding\n",
    "\n",
    "one_hot_result1 = kmeans_onehot_mix(df, \n",
    "                                   cat_columns, \n",
    "                                   5, \n",
    "                                   scale = None, \n",
    "                                   df_output    = False)\n",
    "print(list(one_hot_result1['clusters'])[:10], y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k prototype result\n",
    "\n",
    "\"\"\"Model : 3\"\"\"\n",
    "\n",
    "k_proc_result = k_prot_model(df, cat_columns, 5)\n",
    "print(list(k_proc_result['clusters'])[:10], y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Model : 4\"\"\"\n",
    "\n",
    "y_tr = kmeans_famd(df, cat_columns, 5, 'auto')\n",
    "print(list(y_tr['clusters'])[:10], y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why not just calculate mean and sd for each grouping, zscore by group, \n",
    "# and manually inspect points w abs(z score) > threshold (eg, 2, 3, etc).\n",
    "\n",
    "# You could also calculate skew by group ((mean - median)/sd). \n",
    "# If there are outliers, you'd have large skew values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_pre[0].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_freq(df, column_name):\n",
    "    df[f'{column_name}_freq'] = df[column_name].map(df[column_name].value_counts())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_freq(df, 'Churn?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kmodes.util.dissim import ng_dissim\n",
    "from kmodes.kmodes import KModes\n",
    "\n",
    "def kmodels_model(df, init='Huang', \n",
    "                  n_init=1, \n",
    "                  verbose=2, \n",
    "                  cat_dissim = None, \n",
    "                  df_output = True):\n",
    "    \n",
    "    if cat_dissim:\n",
    "        model = KModes(n_clusters=K,\n",
    "                       init='Huang',\n",
    "                       n_init=1,\n",
    "                       cat_dissim=ng_dissim,\n",
    "                       verbose=2)\n",
    "    else:\n",
    "        model = KModes(n_clusters=K,\n",
    "                       init='Huang',\n",
    "                       n_init=1,\n",
    "                       verbose=2)\n",
    "        \n",
    "    clusters = model.fit_predict(df)\n",
    "    \n",
    "    if df_output:\n",
    "        df['clusters']   = list(clusters)\n",
    "        return df, model\n",
    "    \n",
    "    return {'clusters': clusters, \n",
    "            'model'   : model}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df.mean()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pd.DataFrame(df.mean()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pd.DataFrame(df.mean()).T\n",
    "n = pd.DataFrame(df.std()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cdf = pd.concat([m]*3, ignore_index=True)\n",
    "new_cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Sex': ['M','M','M','F','F','F','F'], 'Age': [33,42,19,64,12,30,32], 'Height': ['163','167','184','164','162','158','160'],})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Height'] = df['Height'].astype(float)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(33 + 42 + 19 )/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Sex', 'Age', 'Height']].groupby('Sex').mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = df[['Sex', 'Age', 'Height']].groupby('Sex').transform(\n",
    "    lambda group: (group.mean()))\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".transform(\n",
    "    lambda group: (group - group.mean()).div(group.std()))\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = z.abs() > stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, cat_columns, con_feats, y = get_dummy_data(50, \n",
    "                                               8, \n",
    "                                               6,\n",
    "                                               centers        = 3,\n",
    "                                               missing_values = None, \n",
    "                                               id_cols        = None)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['X0', 'X2', 'X4', 'X5', 'X6', 'X7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['X0', 'X2', 'X4', 'X5', 'X6', 'X7']\n",
    "\n",
    "col_1 = cat_columns[0]\n",
    "col_2 = cat_columns[1]\n",
    "col_3 = cat_columns[2]\n",
    "col_4 = cat_columns[3]\n",
    "col_5 = cat_columns[4]\n",
    "col_6 = cat_columns[5]\n",
    "\n",
    "df1 = df[(df[col_1] == 0) & (df[col_2] == 0)]\n",
    "df2 = df[(df[col_1] == 1) & (df[col_3] == 1)]\n",
    "df3 = df[(df[col_1] == 1) & (df[col_4] == 1)]\n",
    "df4 = df[(df[col_1] == 1) & (df[col_6] == 0)]\n",
    "\n",
    "df5 = df[(df[col_6] == 1) & (df[col_5] == 0)]\n",
    "df6 = df[(df[col_2] == 1) & (df[col_4] == 0)]\n",
    "df7 = df[(df[col_4] == 1) & (df[col_6] == 0)]\n",
    "\n",
    "df8 = df[(df[col_3] == 1) & (df[col_5] == 0)]\n",
    "df9 = df[(df[col_3] == 1) & (df[col_4] == 1)]\n",
    "\n",
    "df10 = df[(df[col_5] == 1) & (df[col_2] == 0)]\n",
    "\n",
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_freq(df, column_name):\n",
    "    \n",
    "    for col in cat_columns:\n",
    "        df[f'{col}_freq'] = df[col].map(df[col].value_counts())\n",
    "        df = df.drop(col, axis = 1)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "all_groups  = [df1, df2, df3, df4, df5, \n",
    "              df6, df7, df8, df9, df10]\n",
    "\n",
    "all_freq_df = [add_freq(group, cat_columns) for group in all_groups]\n",
    "all_mean_df = [pd.DataFrame(group.mean()).T for group in all_freq_df] \n",
    "all_groups  = pd.concat(all_mean_df).reset_index(drop=True)\n",
    "all_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storring mean and std for every col as a tuple, 0 index for max value,\n",
    "# and 1 for min value\n",
    "outliers = []\n",
    "coa      = []\n",
    "for col in all_groups.columns:\n",
    "    mean = np.mean(all_groups[col].values)\n",
    "    std = np.std(all_groups[col].values)\n",
    "    outliers.append((mean + std, mean - std))\n",
    "    coa.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data= all_groups['X0_freq'].values\n",
    "_mean, _std = np.mean(data), np.std(data)\n",
    "border = _std * 3\n",
    "lower, upper = _mean - border, _mean + border\n",
    "#  outliers\n",
    "outliers = [x for x in data if x < lower or x > upper]\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(outliers,coa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "all_groups[(np.abs(stats.zscore(all_groups)) < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_freq(df, column_name):\n",
    "    df[f'{column_name}_freq'] = df[column_name].map(df[column_name].value_counts())\n",
    "    df = df.drop(column_name, axis = 1)\n",
    "    return df\n",
    "\n",
    "\n",
    "# df = add_freq(df, 'X0')\n",
    "# df = add_freq(df, 'X1')\n",
    "# df = add_freq(df, 'X2')\n",
    "# df = add_freq(df, 'X5')\n",
    "# df = df.drop(['X0','X1','X3', 'X4'], axis = 1)\n",
    "# df.head(5)\n",
    "\n",
    "\n",
    "\n",
    "def gen(df, k):\n",
    "    ui = []\n",
    "    for i in range(k):\n",
    "        dfg = df.sample(i+2)\n",
    "#         dfg = add_freq(dfg, 'X0')\n",
    "#         dfg = add_freq(dfg, 'X2')\n",
    "#         dfg = add_freq(dfg, 'X3')\n",
    "#         dfg = add_freq(dfg, 'X5')\n",
    "        ui.append(dfg)\n",
    "    return ui\n",
    "\n",
    "\n",
    "trt = gen(df, 10)\n",
    "def gene_all(dfs):\n",
    "    final_d = []\n",
    "    \n",
    "    for k in dfs:\n",
    "        final_d.append(pd.DataFrame(k.mean()).T)\n",
    "    return final_d\n",
    "\n",
    "tw = gene_all(trt)\n",
    "drt= pd.concat(tw).reset_index(drop=True)\n",
    "drt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "df[(np.abs(stats.zscore(df)) < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "z_scores = stats.zscore(drt)\n",
    "\n",
    "z_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_z_scores = np.abs(z_scores)\n",
    "abs_z_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_entries = (abs_z_scores < 2).all(axis=1)\n",
    "new_df = drt[filtered_entries]\n",
    "\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_detect(df):\n",
    "    for i in df.describe().columns:\n",
    "        Q1=df.describe().at['25%',i]\n",
    "        Q3=df.describe().at['75%',i]\n",
    "        \n",
    "        print(Q1, Q3)\n",
    "        IQR=Q3 - Q1\n",
    "        LTV=Q1 - 1.5 * IQR\n",
    "        UTV=Q3 + 1.5 * IQR\n",
    "        x=np.array(df[i])\n",
    "        p=[]\n",
    "        for j in x:\n",
    "            if j < LTV or j>UTV:\n",
    "                p.append(df[i].median())\n",
    "            else:\n",
    "                p.append(j)\n",
    "        df[i]=p\n",
    "    return df\n",
    "\n",
    "outlier_detect(drt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pd.DataFrame(df.mean()).T\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = pd.DataFrame(df.std()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cdf = pd.concat([m]*3, ignore_index=True)\n",
    "new_cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ty =  {'X0': {0: 1, 1: 1, 2: 1, 3: 1, 4: 0, 5: 1, 6: 1, 7: 1, 8: 0, 9: 1, 10: 0, 11: 1, 12: 0, 13: 1, 14: 1, 15: 1, 16: 0, 17: 0, 18: 0, 19: 1, 20: 0, 21: 1, 22: 1, 23: 1, 24: 1, 25: 0, 26: 1, 27: 1, 28: 1, 29: 1, 30: 0, 31: 1, 32: 0, 33: 1, 34: 0, 35: 1, 36: 1, 37: 0, 38: 1, 39: 0, 40: 1, 41: 0, 42: 1, 43: 0, 44: 0, 45: 1, 46: 1, 47: 1, 48: 1, 49: 0}, 'X1': {0: -0.037112917323895135, 1: -0.10487134240202785, 2: -1.2231079338781112, 3: -1.4422747724730558, 4: 1.1903093112171788, 5: 0.16264503017608584, 6: 0.09575885513801816, 7: -0.04065753545650327, 8: 0.9811627656097434, 9: -1.0895731715012618, 10: 1.2771663221280398, 11: 0.20642136730493899, 12: 1.4502341066082816, 13: 0.393823431298906, 14: 0.3451716634317143, 15: 0.4709902758164765, 16: 0.9982956103799087, 17: 1.189077916373609, 18: 0.9234439359961105, 19: -1.3255857892440723, 20: 1.2098373846214483, 21: -1.0264301443260604, 22: -1.2752711175444444, 23: -1.1775143284917524, 24: 0.259560479915767, 25: 0.8873566136283076, 26: 0.21516987874467863, 27: -1.1480968752611762, 28: -1.1903434754082, 29: 0.16553499639585526, 30: -0.027563846470247143, 31: 0.19474819789386086, 32: 1.5332001783034717, 33: -1.4746621814990961, 34: 0.9251147862187328, 35: 0.009242841373200278, 36: -1.4155649459675044, 37: 1.1476020465617858, 38: -1.3349528515873126, 39: 1.3090049690691499, 40: -1.0159692538569027, 41: 1.006261902461321, 42: -1.161160155994317, 43: 0.8833114074575376, 44: 1.0811966452823563, 45: -1.368200135415236, 46: -1.556580287072397, 47: -1.2006674694322674, 48: 0.13038922844618558, 49: 0.9941283827531714}, 'X2': {0: 1, 1: 1, 2: 0, 3: 0, 4: 0, 5: 1, 6: 1, 7: 1, 8: 0, 9: 0, 10: 0, 11: 1, 12: 0, 13: 1, 14: 1, 15: 1, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0, 24: 1, 25: 0, 26: 1, 27: 0, 28: 0, 29: 1, 30: 1, 31: 1, 32: 0, 33: 0, 34: 0, 35: 1, 36: 0, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 0, 48: 1, 49: 0}, 'X3': {0: 0, 1: 0, 2: 1, 3: 1, 4: 1, 5: 0, 6: 0, 7: 0, 8: 0, 9: 1, 10: 0, 11: 0, 12: 1, 13: 0, 14: 0, 15: 0, 16: 1, 17: 0, 18: 1, 19: 1, 20: 1, 21: 1, 22: 1, 23: 0, 24: 0, 25: 1, 26: 0, 27: 1, 28: 1, 29: 0, 30: 0, 31: 0, 32: 1, 33: 1, 34: 1, 35: 0, 36: 1, 37: 1, 38: 1, 39: 0, 40: 1, 41: 1, 42: 1, 43: 1, 44: 1, 45: 1, 46: 1, 47: 1, 48: 0, 49: 1}, 'X4': {0: 1, 1: 1, 2: 1, 3: 1, 4: 0, 5: 1, 6: 1, 7: 1, 8: 0, 9: 1, 10: 0, 11: 1, 12: 0, 13: 1, 14: 1, 15: 1, 16: 0, 17: 0, 18: 0, 19: 1, 20: 0, 21: 1, 22: 1, 23: 1, 24: 1, 25: 0, 26: 1, 27: 1, 28: 1, 29: 1, 30: 1, 31: 1, 32: 0, 33: 1, 34: 0, 35: 1, 36: 1, 37: 0, 38: 1, 39: 0, 40: 1, 41: 0, 42: 1, 43: 0, 44: 0, 45: 1, 46: 1, 47: 1, 48: 1, 49: 0}, 'X5': {0: -1.6251996907891026, 1: -1.4952824550113089, 2: 0.5929477365851917, 3: 0.5188383985894559, 4: 0.8379329230408614, 5: -1.459754180360659, 6: -1.3954747896019781, 7: -1.4228738797414382, 8: 0.7961049502619677, 9: 0.5969844287269782, 10: 0.6254616540670719, 11: -1.1973174138607352, 12: 0.6743779844553507, 13: -1.3773048616218415, 14: -1.5502881165079259, 15: -1.410649926526345, 16: 0.966418551153225, 17: 0.8413042649713098, 18: 0.5947398261267023, 19: 0.5285211133411081, 20: 0.8154880527487283, 21: 0.685523955516477, 22: 0.7052301139466511, 23: 0.5694387744666269, 24: -1.3660759251156689, 25: 0.7376392137717523, 26: -1.2965881798979835, 27: 0.3247985508699227, 28: 0.8492845744063385, 29: -1.3631982627466268, 30: -1.5593937453283628, 31: -1.5647378670163918, 32: 0.7184017737689418, 33: 0.5401478202493889, 34: 0.8549277265014412, 35: -1.4324174459510242, 36: 0.5699907448414805, 37: 0.5278269967299144, 38: 0.6544095431196703, 39: 0.9956765313323911, 40: 0.49341021793456574, 41: 0.8777030715347666, 42: 0.5628001790223106, 43: 0.6932468790071539, 44: 0.5944907552098264, 45: 0.6628094310909329, 46: 0.660678722318602, 47: 0.68454503898171, 48: -1.5961965190965848, 49: 0.7606527604851616}, 'X6': {0: 0, 1: 0, 2: 0, 3: 0, 4: 1, 5: 0, 6: 0, 7: 0, 8: 1, 9: 0, 10: 1, 11: 0, 12: 1, 13: 0, 14: 0, 15: 0, 16: 1, 17: 1, 18: 1, 19: 0, 20: 1, 21: 0, 22: 0, 23: 0, 24: 0, 25: 1, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 1, 33: 0, 34: 1, 35: 0, 36: 0, 37: 1, 38: 0, 39: 1, 40: 0, 41: 1, 42: 0, 43: 1, 44: 1, 45: 0, 46: 0, 47: 0, 48: 0, 49: 1}, 'X7': {0: 0, 1: 0, 2: 1, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 1, 22: 0, 23: 1, 24: 0, 25: 0, 26: 0, 27: 0, 28: 1, 29: 0, 30: 0, 31: 0, 32: 0, 33: 1, 34: 0, 35: 0, 36: 1, 37: 0, 38: 1, 39: 0, 40: 1, 41: 0, 42: 0, 43: 0, 44: 0, 45: 1, 46: 0, 47: 1, 48: 0, 49: 0}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "df= all_groups.drop\n",
    "column_values = [column for column in df.columns.tolist() ]\n",
    "\n",
    "\n",
    "df['Correlation_coefficent'], df['P-value'] = zip(*df.T.apply(lambda x: pearsonr(x[column_values ],x[column_values ])))\n",
    "df_result = df[['Correlation_coefficent','P-value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import DistanceMetric\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calculate_gower_distance(df):\n",
    "  \n",
    "  '''\n",
    "  Takes a dataframe as an input and returns the gower distance\n",
    "  matrix.\n",
    "  \n",
    "  '''\n",
    "\n",
    "  variable_distances = []\n",
    "  \n",
    "  for col in range(df.shape[1]):\n",
    "    \n",
    "    feature = df.iloc[:,[col]]\n",
    "    if feature.dtypes.values == np.object:\n",
    "      \n",
    "      feature_dist = DistanceMetric.get_metric('dice').pairwise(pd.get_dummies(feature, drop_first=True))\n",
    "        \n",
    "    else:\n",
    "      \n",
    "      feature_dist = DistanceMetric.get_metric('manhattan').pairwise(feature) / max(np.ptp(feature.values),1)\n",
    "\n",
    "\n",
    "      variable_distances.append(feature_dist)\n",
    "      \n",
    "\n",
    "  return np.array(variable_distances).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_gower_distance(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gower\n",
    "gower.gower_matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "def calculate_zscore(df, columns):\n",
    "  '''\n",
    "  scales columns in dataframe using z-score\n",
    "  '''\n",
    "  df = df.copy()\n",
    "  for col in columns:\n",
    "      df[col] = (df[col] - df[col].mean())/df[col].std(ddof=0)\n",
    "\n",
    "  return df\n",
    "\n",
    "\n",
    "\n",
    "def one_hot_encode(df, columns):\n",
    "  '''\n",
    "  one hot encodes list of columns and\n",
    "  concatenates them to the original df\n",
    "  '''\n",
    "\n",
    "  concat_df = pd.concat([pd.get_dummies(df[col], drop_first=True, prefix=col) for col in columns], axis=1)\n",
    "  one_hot_cols = concat_df.columns\n",
    "\n",
    "  return concat_df, one_hot_cols\n",
    "\n",
    "\n",
    "\n",
    "def normalize_column_modality(df, columns):\n",
    "  '''\n",
    "  divides each column by the probability μₘ of the modality \n",
    "  (number of ones in the column divided by N) only for one hot columns\n",
    "  '''\n",
    "\n",
    "  length = len(df)\n",
    "  for col in columns:\n",
    "    \n",
    "    weight = math.sqrt(sum(df[col])/length)\n",
    "    df[col] = df[col]/weight\n",
    "\n",
    "  return df\n",
    "\n",
    "\n",
    "\n",
    "def center_columns(df, columns):\n",
    "  '''\n",
    "  center columns by subtracting the mean value\n",
    "  '''\n",
    "  for col in columns:\n",
    "      df[col] = (df[col] - df[col].mean())\n",
    "\n",
    "  return df\n",
    "\n",
    "\n",
    "\n",
    "def FAMD_(df, n_components=2):\n",
    "  '''\n",
    "  Factorial Analysis of Mixed Data (FAMD), \n",
    "  which generalizes the Principal Component Analysis (PCA) \n",
    "  algorithm to datasets containing numerical and categorical variables\n",
    "\n",
    "  a) For the numerical variables\n",
    "    - Standard scale (= get the z-score)\n",
    "  \n",
    "  b) For the categorical variables:\n",
    "    - Get the one-hot encoded columns\n",
    "    - Divide each column by the square root of its probability sqrt(μₘ)\n",
    "    - Center the columns\n",
    "\n",
    "  c) Apply a PCA algorithm over the table obtained!\n",
    "\n",
    "  '''\n",
    "  \n",
    "  variable_distances = []\n",
    "\n",
    "  numeric_cols = df.select_dtypes(include=np.number)\n",
    "  cat_cols = df.select_dtypes(include='object')\n",
    "  \n",
    "  # numeric process\n",
    "  normalized_df = calculate_zscore(df, numeric_cols)\n",
    "  normalized_df = normalized_df[numeric_cols.columns]\n",
    "\n",
    "  # categorical process\n",
    "  cat_one_hot_df, one_hot_cols = one_hot_encode(df, cat_cols)\n",
    "  cat_one_hot_norm_df = normalize_column_modality(cat_one_hot_df, one_hot_cols)\n",
    "  cat_one_hot_norm_center_df = center_columns(cat_one_hot_norm_df, one_hot_cols)\n",
    "\n",
    "  # Merge DataFrames\n",
    "  processed_df = pd.concat([normalized_df, cat_one_hot_norm_center_df], axis=1)\n",
    "\n",
    "  # Perform (PCA)\n",
    "  pca = PCA(n_components=n_components)\n",
    "  principalComponents = pca.fit_transform(processed_df)\n",
    "\n",
    "  return principalComponents\n",
    "\n",
    "\n",
    "df, cat_columns, con_feats, y = get_dummy_data(50, \n",
    "                                               8, \n",
    "                                               6,\n",
    "                                               centers        = 3,\n",
    "                                               missing_values = None, \n",
    "                                               id_cols        = None)\n",
    "df.head(10)\n",
    "df = cobj(df, cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAMD_(df, n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "famd_feats(df, cat_columns,\n",
    "                   no_of_components = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = umap_reduce(df)\n",
    "result, emd = dat\n",
    "\n",
    "UMAP_clusterer = kmeans_model(emd, \n",
    "                 no_of_clusters = 4, \n",
    "                 random_state = 32, \n",
    "                 max_iter     = 300, \n",
    "                 verbose      = 0, \n",
    "                 df_output    = False)\n",
    "\n",
    "\n",
    "def umap_embd_model(df, \n",
    "                    cat_columns, \n",
    "                    no_of_clusters, \n",
    "                    random_state = 32, \n",
    "                    max_iter     = 300, \n",
    "                    verbose      = 0, \n",
    "                    df_output    = False):\n",
    "    \n",
    "    \n",
    "    df             = cobj(df, cat_columns)\n",
    "    _, emd         = dat\n",
    "    \n",
    "    UMAP_clusterer = kmeans_model(emd, \n",
    "                                 no_of_clusters = no_of_clusters, \n",
    "                                 random_state = random_state, \n",
    "                                 max_iter     = max_iter, \n",
    "                                 verbose      = verbose, \n",
    "                                 df_output    = df_output)\n",
    "    \n",
    "    return UMAP_clusterer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, emd = dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP_clusterer = KMeans(n_clusters=num_clusters, init='k-means++',\n",
    "#                         verbose=0, random_state=random_state,\n",
    "#                         algorithm='auto').fit(embedding_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UMAP_clusterer = kmeans_model(emd, \n",
    "                 no_of_clusters = 4, \n",
    "                 random_state = 32, \n",
    "                 max_iter     = 300, \n",
    "                 verbose      = 0, \n",
    "                 df_output    = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = evaluate_clusters(scores,  list(UMAP_clusterer['clusters']),\n",
    "                           labels, name='ump', \n",
    "                           X=emd)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continous_data = df.copy()\n",
    "\n",
    "numeric_cols = continous_data.select_dtypes(include=np.number)\n",
    "cat_cols = continous_data.select_dtypes(include='object')\n",
    "  \n",
    "# numeric process\n",
    "normalized_df = calculate_zscore(continous_data, numeric_cols)\n",
    "normalized_df = normalized_df[numeric_cols.columns]\n",
    "\n",
    "# categorical process\n",
    "cat_one_hot_df, one_hot_cols = one_hot_encode(continous_data, cat_cols)\n",
    "cat_one_hot_norm_df = calculate_zscore(cat_one_hot_df, one_hot_cols)\n",
    "\n",
    "# Merge DataFrames\n",
    "processed_df = pd.concat([normalized_df, cat_one_hot_norm_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UMAP_clusterer2 = kmeans_model(processed_df, \n",
    "                 no_of_clusters = 4, \n",
    "                 random_state = 32, \n",
    "                 max_iter     = 300, \n",
    "                 verbose      = 0, \n",
    "                 df_output    = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = evaluate_clusters(scores,  list(UMAP_clusterer2['clusters']),\n",
    "                           labels, name='cat2enc', \n",
    "                           X=processed_df)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_protype_data = df.copy()\n",
    "\n",
    "def column_index(df, query_cols):\n",
    "    cols = df.columns.values\n",
    "    sidx = np.argsort(cols)\n",
    "    return sidx[np.searchsorted(cols,query_cols,sorter=sidx)]\n",
    "\n",
    "numeric_cols = k_protype_data.select_dtypes(include=np.number)\n",
    "cat_cols = k_protype_data.select_dtypes(include='object')\n",
    "\n",
    "norm_num_cols = calculate_zscore(numeric_cols, numeric_cols)\n",
    "processed_df = pd.concat([norm_num_cols, cat_cols], axis=1)\n",
    "\n",
    "categorical_indices = column_index(processed_df, cat_cols.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mk = k_prot_model(processed_df, \n",
    "           list(cat_cols.columns), \n",
    "           4, \n",
    "           init_method  = 'Cao',\n",
    "           random_state = 32,\n",
    "            max_iter    = 300,\n",
    "            n_jobs       = 1,\n",
    "            verbose     = 0, \n",
    "            df_output   = False, \n",
    "            n_init      = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores1 = evaluate_clusters(scores,  list(mk[\"clusters\"]),\n",
    "                           labels, name='K_Prototype', \n",
    "                           X=None)\n",
    "\n",
    "scores1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
